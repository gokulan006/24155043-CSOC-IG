{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41574bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0832f4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# checking the gpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9d1045",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fb19eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79394f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientId</th>\n",
       "      <th>AppointmentID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>ScheduledDay</th>\n",
       "      <th>AppointmentDay</th>\n",
       "      <th>Age</th>\n",
       "      <th>Neighbourhood</th>\n",
       "      <th>Scholarship</th>\n",
       "      <th>Hipertension</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Alcoholism</th>\n",
       "      <th>Handcap</th>\n",
       "      <th>SMS_received</th>\n",
       "      <th>No-show</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.987250e+13</td>\n",
       "      <td>5642903</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-29T18:38:08Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>62</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.589978e+14</td>\n",
       "      <td>5642503</td>\n",
       "      <td>M</td>\n",
       "      <td>2016-04-29T16:08:27Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>56</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.262962e+12</td>\n",
       "      <td>5642549</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-29T16:19:04Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>62</td>\n",
       "      <td>MATA DA PRAIA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.679512e+11</td>\n",
       "      <td>5642828</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-29T17:29:31Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>8</td>\n",
       "      <td>PONTAL DE CAMBURI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.841186e+12</td>\n",
       "      <td>5642494</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-29T16:07:23Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>56</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PatientId  AppointmentID Gender          ScheduledDay  \\\n",
       "0  2.987250e+13        5642903      F  2016-04-29T18:38:08Z   \n",
       "1  5.589978e+14        5642503      M  2016-04-29T16:08:27Z   \n",
       "2  4.262962e+12        5642549      F  2016-04-29T16:19:04Z   \n",
       "3  8.679512e+11        5642828      F  2016-04-29T17:29:31Z   \n",
       "4  8.841186e+12        5642494      F  2016-04-29T16:07:23Z   \n",
       "\n",
       "         AppointmentDay  Age      Neighbourhood  Scholarship  Hipertension  \\\n",
       "0  2016-04-29T00:00:00Z   62    JARDIM DA PENHA            0             1   \n",
       "1  2016-04-29T00:00:00Z   56    JARDIM DA PENHA            0             0   \n",
       "2  2016-04-29T00:00:00Z   62      MATA DA PRAIA            0             0   \n",
       "3  2016-04-29T00:00:00Z    8  PONTAL DE CAMBURI            0             0   \n",
       "4  2016-04-29T00:00:00Z   56    JARDIM DA PENHA            0             1   \n",
       "\n",
       "   Diabetes  Alcoholism  Handcap  SMS_received No-show  \n",
       "0         0           0        0             0      No  \n",
       "1         0           0        0             0      No  \n",
       "2         0           0        0             0      No  \n",
       "3         0           0        0             0      No  \n",
       "4         1           0        0             0      No  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the data\n",
    "df=pd.read_csv('KaggleV2-May-2016.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfed523e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 110527 entries, 0 to 110526\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   PatientId       110527 non-null  float64\n",
      " 1   AppointmentID   110527 non-null  int64  \n",
      " 2   Gender          110527 non-null  object \n",
      " 3   ScheduledDay    110527 non-null  object \n",
      " 4   AppointmentDay  110527 non-null  object \n",
      " 5   Age             110527 non-null  int64  \n",
      " 6   Neighbourhood   110527 non-null  object \n",
      " 7   Scholarship     110527 non-null  int64  \n",
      " 8   Hipertension    110527 non-null  int64  \n",
      " 9   Diabetes        110527 non-null  int64  \n",
      " 10  Alcoholism      110527 non-null  int64  \n",
      " 11  Handcap         110527 non-null  int64  \n",
      " 12  SMS_received    110527 non-null  int64  \n",
      " 13  No-show         110527 non-null  object \n",
      "dtypes: float64(1), int64(8), object(5)\n",
      "memory usage: 11.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cdcd88",
   "metadata": {},
   "source": [
    "#### Dropping unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b69561ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Neighbourhood</th>\n",
       "      <th>Scholarship</th>\n",
       "      <th>Hipertension</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Alcoholism</th>\n",
       "      <th>Handcap</th>\n",
       "      <th>SMS_received</th>\n",
       "      <th>No-show</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>62</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>62</td>\n",
       "      <td>MATA DA PRAIA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>8</td>\n",
       "      <td>PONTAL DE CAMBURI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>56</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender  Age      Neighbourhood  Scholarship  Hipertension  Diabetes  \\\n",
       "0      F   62    JARDIM DA PENHA            0             1         0   \n",
       "1      M   56    JARDIM DA PENHA            0             0         0   \n",
       "2      F   62      MATA DA PRAIA            0             0         0   \n",
       "3      F    8  PONTAL DE CAMBURI            0             0         0   \n",
       "4      F   56    JARDIM DA PENHA            0             1         1   \n",
       "\n",
       "   Alcoholism  Handcap  SMS_received No-show  \n",
       "0           0        0             0      No  \n",
       "1           0        0             0      No  \n",
       "2           0        0             0      No  \n",
       "3           0        0             0      No  \n",
       "4           0        0             0      No  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['PatientId','AppointmentID','ScheduledDay','AppointmentDay'],inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d480e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No-show\n",
       "No     88208\n",
       "Yes    22319\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['No-show'].value_counts()\n",
    "# The target class is imbalanced in the ratio of 4:1 which is high class imbalance in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516eab62",
   "metadata": {},
   "source": [
    "#### Label Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ce9cb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "df['Gender']=le.fit_transform(df['Gender'])\n",
    "df['No-show']=le.fit_transform(df['No-show'])\n",
    "df['Neighbourhood']=le.fit_transform(df['Neighbourhood'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b27b258b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((110527, 9), (110527,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separating the features and target\n",
    "X=df.drop(columns=['No-show'])\n",
    "y=df['No-show']\n",
    "\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29ae754",
   "metadata": {},
   "source": [
    "#### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "438b29f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scalar=StandardScaler()\n",
    "X=scalar.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f01caa6",
   "metadata": {},
   "source": [
    "#### Splitting into train and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6818431c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((88421, 9), (22106, 9), (88421,), (22106,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.2,stratify=y)\n",
    "X_train.shape,X_val.shape,y_train.shape,y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b75b10",
   "metadata": {},
   "source": [
    "#### Part 1: From Scratch Implementation\n",
    "with using class weights to address the class imbalance for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f7eff43",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cb3bfed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((88421, 9), (22106, 9), (88421,), (22106,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_val.shape,y_train.shape,y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "134b0e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(input_size, hidden_layers=[128, 64]):\n",
    "     \n",
    "    weights = []\n",
    "    biases = []\n",
    "    layers = [input_size] + hidden_layers + [1]  \n",
    "    \n",
    "    for i in range(len(layers)-1):\n",
    "        weights.append(np.random.randn(layers[i], layers[i+1])* 0.01)\n",
    "        biases.append(np.zeros((1, layers[i+1])))\n",
    "    \n",
    "    return weights, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88f0dc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def ReLU(x):\n",
    "    return np.maximum(0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "199a7bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weighted_loss(y_true, y_pred, class_weights):\n",
    "    \n",
    "    y_true = np.asarray(y_true).reshape(-1, 1)\n",
    "    y_pred = np.asarray(y_pred).reshape(-1, 1)\n",
    "    sample_weights = np.where(y_true == 1, class_weights[1], class_weights[0])\n",
    "    return np.mean(sample_weights * (y_true - y_pred)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f42832f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, weights, biases):\n",
    "\n",
    "    z_layers = []\n",
    "    activations = [X]\n",
    "    \n",
    "    for i in range(len(weights)-1):\n",
    "        z = np.dot(activations[-1], weights[i]) + biases[i]\n",
    "        a = ReLU(z)  \n",
    "        z_layers.append(z)\n",
    "        activations.append(a)\n",
    "    \n",
    "     \n",
    "    z = np.dot(activations[-1], weights[-1]) + biases[-1]\n",
    "    a = sigmoid(z)\n",
    "    z_layers.append(z)\n",
    "    activations.append(a)\n",
    "    \n",
    "    return activations, z_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "643b8d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(X, y, activations, z_layers, weights, biases, class_weights, learning_rate=0.001):\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    y = y.reshape(-1, 1)\n",
    "    \n",
    "    sample_weights = np.where(y == 1, class_weights[1], class_weights[0])\n",
    "    \n",
    "    grad_w = [np.zeros_like(w) for w in weights]\n",
    "    grad_b = [np.zeros_like(b) for b in biases]\n",
    "    \n",
    "    dA = -(sample_weights * (y - activations[-1]) / m)\n",
    "    dZ = dA * (activations[-1] * (1 - activations[-1]))  \n",
    "    \n",
    "    grad_w[-1] = np.dot(activations[-2].T, dZ)\n",
    "    grad_b[-1] = np.sum(dZ, axis=0, keepdims=True)\n",
    "    \n",
    "    for l in range(len(weights)-2, -1, -1):\n",
    "        dA = np.dot(dZ, weights[l+1].T)\n",
    "        dZ = dA * (z_layers[l] > 0)  \n",
    "        grad_w[l] = np.dot(activations[l].T, dZ)\n",
    "        grad_b[l] = np.sum(dZ, axis=0, keepdims=True)\n",
    "    \n",
    "    for i in range(len(weights)):\n",
    "        weights[i] -= learning_rate * grad_w[i]\n",
    "        biases[i] -= learning_rate * grad_b[i]\n",
    "    \n",
    "    return weights, biases\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "166f2ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "weights = compute_class_weight('balanced', classes=classes, y=y_train)\n",
    "class_weights = {0: weights[0], 1: weights[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5dfd0a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss = 0.2500, Val Loss = 0.2500\n",
      "Epoch 10: Train Loss = 0.2500, Val Loss = 0.2500\n",
      "Epoch 20: Train Loss = 0.2500, Val Loss = 0.2500\n",
      "Epoch 30: Train Loss = 0.2500, Val Loss = 0.2500\n",
      "Epoch 40: Train Loss = 0.2500, Val Loss = 0.2500\n",
      "Epoch 50: Train Loss = 0.2500, Val Loss = 0.2500\n",
      "Epoch 60: Train Loss = 0.2500, Val Loss = 0.2500\n",
      "Epoch 70: Train Loss = 0.2500, Val Loss = 0.2500\n",
      "Epoch 80: Train Loss = 0.2500, Val Loss = 0.2500\n",
      "Epoch 90: Train Loss = 0.2500, Val Loss = 0.2500\n",
      "Training complete. Best Val Loss: 0.2500\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.001\n",
    "X_train = np.array(X_train, dtype=np.float32)\n",
    "y_train = np.array(y_train).reshape(-1, 1)\n",
    "X_val = np.array(X_val, dtype=np.float32)\n",
    "y_val = np.array(y_val).reshape(-1, 1)\n",
    "\n",
    " \n",
    "hidden_layers=[128,64]\n",
    "epochs=100\n",
    "\n",
    "weights, biases = initialize_parameters(input_size, hidden_layers)\n",
    "\n",
    "best_weights, best_biases = None, None\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    activations, z_layers = forward_propagation(X_train, weights, biases)\n",
    "        \n",
    "    train_loss = compute_weighted_loss(y_train, activations[-1], class_weights)\n",
    "    val_activations, _ = forward_propagation(X_val, weights, biases)\n",
    "    val_loss = compute_weighted_loss(y_val, val_activations[-1], class_weights)\n",
    "        \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_weights = [w.copy() for w in weights]\n",
    "        best_biases = [b.copy() for b in biases]\n",
    "    \n",
    "    weights, biases = backward_propagation(X_train, y_train, activations, z_layers, weights, biases, class_weights,learning_rate=learning_rate)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n",
    "\n",
    "print(f\"Training complete. Best Val Loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0259bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, roc_auc_score, confusion_matrix\n",
    "def evaluate_model(X_test, y_test, weights, biases, threshold=0.5):\n",
    "     \n",
    "    activations, _ = forward_propagation(X_test, weights, biases)\n",
    "    y_pred_cont = activations[-1]\n",
    "    \n",
    "    y_pred_bin = (y_pred_cont > threshold).astype(int)\n",
    "    \n",
    "    report= classification_report(y_test, y_pred_bin)\n",
    "    f1score=f1_score(y_test, y_pred_bin)\n",
    "    roc=roc_auc_score(y_test, y_pred_cont)\n",
    "    matrix= confusion_matrix(y_test, y_pred_bin)\n",
    "    metrics = {\n",
    "        'classification_report':report,\n",
    "        'f1_score': f1score,\n",
    "        'roc_auc': roc,   \n",
    "        'confusion_matrix': matrix\n",
    "    }\n",
    "    \n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1483d011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.14      0.24     17642\n",
      "           1       0.21      0.89      0.34      4464\n",
      "\n",
      "    accuracy                           0.29     22106\n",
      "   macro avg       0.53      0.52      0.29     22106\n",
      "weighted avg       0.71      0.29      0.26     22106\n",
      "\n",
      "F1 Score: 0.3386481214485625\n",
      "ROC AUC: 0.5633827500681617\n",
      "Confusion Matrix:\n",
      " [[ 2517 15125]\n",
      " [  471  3993]]\n"
     ]
    }
   ],
   "source": [
    "# 4. Evaluate\n",
    "metrics = evaluate_model(X_val, y_val, best_weights, best_biases)\n",
    "print(\"Classification Report:\\n\", metrics['classification_report'])\n",
    "print(\"F1 Score:\", metrics['f1_score'])\n",
    "print(\"ROC AUC:\", metrics['roc_auc'])\n",
    "print(\"Confusion Matrix:\\n\", metrics['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557c1b8c",
   "metadata": {},
   "source": [
    "#### Part 2: PyTorch Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "574064a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class ANN_model(nn.Module):\n",
    "\n",
    "  def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(64,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "  def forward(self, x):\n",
    "      return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb753b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "y_train_np = y_train.values if hasattr(y_train, 'values') else np.array(y_train)\n",
    "y_train_np = y_train_np.ravel()  \n",
    "\n",
    "classes = np.unique(y_train_np)\n",
    "weights = compute_class_weight('balanced', classes=classes, y=y_train_np)\n",
    "\n",
    "class_weights = torch.tensor(weights, dtype=torch.float).to('cpu')\n",
    "sample_weights = class_weights[y_train_np].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b44f31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=X_train.shape[1]\n",
    "model=ANN_model(input_shape)\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001)\n",
    "criterion=nn.BCELoss(weight=sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f9c7d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch is 0 and loss is 0.6962325572967529\n",
      "epoch is 10 and loss is 0.6788383722305298\n",
      "epoch is 20 and loss is 0.6770852208137512\n",
      "epoch is 30 and loss is 0.6758477687835693\n",
      "epoch is 40 and loss is 0.6752893924713135\n",
      "epoch is 50 and loss is 0.674804151058197\n",
      "epoch is 60 and loss is 0.6744301319122314\n",
      "epoch is 70 and loss is 0.6740926504135132\n",
      "epoch is 80 and loss is 0.6737724542617798\n",
      "epoch is 90 and loss is 0.6734555959701538\n"
     ]
    }
   ],
   "source": [
    "num_epochs =100\n",
    "loss_his=[]\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    model.train()\n",
    "    inputs = torch.from_numpy(X_train).float()\n",
    "    labels = torch.from_numpy(y_train).float().view(-1, 1)\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_his.append(loss)\n",
    "    if epoch%10==0:\n",
    "        print(f\"epoch is {epoch} and loss is {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b58e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.70      0.76     17642\n",
      "           1       0.27      0.46      0.34      4464\n",
      "\n",
      "    accuracy                           0.65     22106\n",
      "   macro avg       0.55      0.58      0.55     22106\n",
      "weighted avg       0.72      0.65      0.67     22106\n",
      "\n",
      "f1 Score 0.3431025770591208\n",
      "ROC AUC Score 0.5758799489366163\n",
      "Confusion Matrix\n",
      " [[12269  5373]\n",
      " [ 2427  2037]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, roc_auc_score,confusion_matrix\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    inputs=torch.from_numpy(X_val).float()\n",
    "    outputs=model(inputs)\n",
    "    y_pred_prob=outputs.numpy()\n",
    "    y_pred=(y_pred_prob>0.5)\n",
    "\n",
    "report=classification_report(y_val,y_pred)\n",
    "f1score=f1_score(y_val,y_pred)\n",
    "roc=roc_auc_score(y_val,y_pred)\n",
    "matrix=confusion_matrix(y_val,y_pred)\n",
    "print(\"classification report\",report)\n",
    "print(\"f1 Score\",f1score)\n",
    "print(\"ROC AUC Score\",roc)\n",
    "print(\"Confusion Matrix\\n\",matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ed4aee",
   "metadata": {},
   "source": [
    "#### Adding Useful Features\n",
    "I noticed that adding useful features is significantly improving the model performance even for a imbalanced dataset\n",
    "SO I decided to add more useful features to distinguish between the patient who would show up versus those who would miss their appointments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ec9c929b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"KaggleV2-May-2016.csv\")\n",
    "\n",
    "df['ScheduledDay'] = pd.to_datetime(df['ScheduledDay'])\n",
    "df['AppointmentDay'] = pd.to_datetime(df['AppointmentDay'])\n",
    "\n",
    "df['days_between'] = (df['AppointmentDay'] - df['ScheduledDay']).dt.days\n",
    "df['days_between'] = np.where(df['days_between'] < 0, 0, df['days_between'])\n",
    "\n",
    "df['waiting_category'] = pd.cut(df['days_between'],\n",
    "    bins=[-1, 0, 1, 3, 7, 14, 30, 1000],\n",
    "    labels=['same_day', '1_day', '2-3_days', '4-7_days', '8-14_days', '15-30_days', '30+_days'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6f696824",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_weekend'] = (df['AppointmentDay'].dt.dayofweek >= 5).astype(int)\n",
    "df['month'] = df['AppointmentDay'].dt.month\n",
    "df['hour_of_day'] = df['ScheduledDay'].dt.hour\n",
    "df['appointment_dayofweek'] = df['AppointmentDay'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c3b8830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_history = df.groupby('PatientId').agg(\n",
    "    total_appointments=('AppointmentID', 'count'),\n",
    "    prev_no_shows=('No-show', lambda x: sum(x == 'Yes'))\n",
    ")\n",
    "df = df.merge(patient_history, on='PatientId', how='left')\n",
    "df['no_show_rate'] = df['prev_no_shows'] / df['total_appointments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f62c8bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['PatientId', 'AppointmentDay'])\n",
    "df['days_since_last'] = df.groupby('PatientId')['AppointmentDay'].diff().dt.days\n",
    "df['days_since_last'] = df['days_since_last'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "df6a1ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = ['Hipertension', 'Diabetes', 'Alcoholism', 'Handcap']\n",
    "df['health_risk_score'] = df[conditions].sum(axis=1)\n",
    "df['senior_with_condition'] = ((df['Age'] >= 60) & (df[conditions].sum(axis=1) > 0)).astype(int)\n",
    "\n",
    "df['last_minute'] = (df['days_between'] <= 1).astype(int)\n",
    "df['appt_freq'] = df.groupby('PatientId')['AppointmentDay'].transform('count')\n",
    "df['prev_same_day'] = df.groupby(['PatientId', df['AppointmentDay'].dt.date])['AppointmentID'].transform('count') - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8b028f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month_sin'] = np.sin(2 * np.pi * df['month']/12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['month']/12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6772c248",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 12, 19, 30, 50, 70, 120]\n",
    "labels = ['child', 'teen', 'young_adult', 'adult', 'senior', 'elderly']\n",
    "df['age_group'] = pd.cut(df['Age'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb07cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['Gender'] = le.fit_transform(df['Gender'])\n",
    "df['age_group']=le.fit_transform(df['age_group'])\n",
    "df['No-show']=le.fit_transform(df['No-show'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b47645",
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import TargetEncoder\n",
    "\n",
    "encoder = TargetEncoder(cols=['Neighbourhood', 'waiting_category'])\n",
    "df[['Neighbourhood', 'waiting_category']] = encoder.fit_transform(df[['Neighbourhood', 'waiting_category']],df['No-show'])\n",
    "\n",
    "df=df.drop(columns=['ScheduledDay', 'AppointmentDay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0a4dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(columns=['No-show'])\n",
    "y=df['No-show']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scalar=StandardScaler()\n",
    "X=scalar.fit_transform(X)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "413cc70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((88421, 29), (22106, 29), (88421,), (22106,))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_val.shape,y_train.shape,y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5b4875a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "y_train_np = y_train.values if hasattr(y_train, 'values') else np.array(y_train)\n",
    "y_train_np = y_train_np.ravel()  \n",
    "\n",
    "classes = np.unique(y_train_np)\n",
    "weights = compute_class_weight('balanced', classes=classes, y=y_train_np)\n",
    "\n",
    "class_weights = torch.tensor(weights, dtype=torch.float).to('cpu')\n",
    "sample_weights = class_weights[y_train_np].reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a453a600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss = 0.2500, Val Loss = 0.2500\n",
      "Epoch 10: Train Loss = 0.2500, Val Loss = 0.2500\n",
      "Epoch 20: Train Loss = 0.2500, Val Loss = 0.2500\n",
      "Epoch 30: Train Loss = 0.2500, Val Loss = 0.2500\n",
      "Epoch 40: Train Loss = 0.2500, Val Loss = 0.2500\n",
      "Epoch 50: Train Loss = 0.2500, Val Loss = 0.2500\n",
      "Epoch 60: Train Loss = 0.2500, Val Loss = 0.2500\n",
      "Epoch 70: Train Loss = 0.2500, Val Loss = 0.2500\n",
      "Epoch 80: Train Loss = 0.2500, Val Loss = 0.2500\n",
      "Epoch 90: Train Loss = 0.2500, Val Loss = 0.2500\n",
      "Training complete. Best Val Loss: 0.2500\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.001\n",
    "X_train = np.array(X_train, dtype=np.float32)\n",
    "y_train = np.array(y_train).reshape(-1, 1)\n",
    "X_val = np.array(X_val, dtype=np.float32)\n",
    "y_val = np.array(y_val).reshape(-1, 1)\n",
    "\n",
    "input_size=X_train.shape[1]\n",
    "hidden_layers=[128,64]\n",
    "epochs=100\n",
    "\n",
    "weights, biases = initialize_parameters(input_size, hidden_layers)\n",
    "\n",
    "best_weights, best_biases = None, None\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    activations, z_layers = forward_propagation(X_train, weights, biases)\n",
    "        \n",
    "    train_loss = compute_weighted_loss(y_train, activations[-1], class_weights)\n",
    "    val_activations, _ = forward_propagation(X_val, weights, biases)\n",
    "    val_loss = compute_weighted_loss(y_val, val_activations[-1], class_weights)\n",
    "        \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_weights = [w.copy() for w in weights]\n",
    "        best_biases = [b.copy() for b in biases]\n",
    "    \n",
    "    weights, biases = backward_propagation(X_train, y_train, activations, z_layers, weights, biases, class_weights,learning_rate=learning_rate)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n",
    "\n",
    "print(f\"Training complete. Best Val Loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "408d5f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85     17642\n",
      "           1       0.23      0.12      0.15      4464\n",
      "\n",
      "    accuracy                           0.74     22106\n",
      "   macro avg       0.52      0.51      0.50     22106\n",
      "weighted avg       0.69      0.74      0.71     22106\n",
      "\n",
      "F1 Score: 0.1540532455877954\n",
      "ROC AUC: 0.44500260101444133\n",
      "Confusion Matrix:\n",
      " [[15935  1707]\n",
      " [ 3949   515]]\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate_model(X_val, y_val, best_weights, best_biases)\n",
    "print(\"Classification Report:\\n\", metrics['classification_report'])\n",
    "print(\"F1 Score:\", metrics['f1_score'])\n",
    "print(\"ROC AUC:\", metrics['roc_auc'])\n",
    "print(\"Confusion Matrix:\\n\", metrics['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "971b7055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class ANN_model(nn.Module):\n",
    "\n",
    "  def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(64,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "  def forward(self, x):\n",
    "      return self.net(x)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd26969e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=X_train.shape[1]\n",
    "model=ANN_model(input_shape)\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001)\n",
    "criterion=nn.BCELoss(weight=sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "99d7be6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch is 0 and loss is 0.6948327422142029\n",
      "epoch is 10 and loss is 0.5904402136802673\n",
      "epoch is 20 and loss is 0.4579855501651764\n",
      "epoch is 30 and loss is 0.33583006262779236\n",
      "epoch is 40 and loss is 0.2652541399002075\n",
      "epoch is 50 and loss is 0.2411290854215622\n",
      "epoch is 60 and loss is 0.23280633985996246\n",
      "epoch is 70 and loss is 0.22654058039188385\n"
     ]
    }
   ],
   "source": [
    "num_epochs =75\n",
    "loss_his=[]\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    model.train()\n",
    "    inputs = torch.from_numpy(X_train).float()\n",
    "    labels = torch.from_numpy(y_train).float().view(-1, 1)\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_his.append(loss)\n",
    "    if epoch%10==0:\n",
    "        print(f\"epoch is {epoch} and loss is {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "34a29c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.93     17642\n",
      "           1       0.66      0.91      0.76      4464\n",
      "\n",
      "    accuracy                           0.89     22106\n",
      "   macro avg       0.82      0.90      0.84     22106\n",
      "weighted avg       0.91      0.89      0.89     22106\n",
      "\n",
      "f1 Score 0.7643252368001501\n",
      "ROC AUC Score 0.8962319549226573\n",
      "Confusion Matrix\n",
      " [[15518  2124]\n",
      " [  389  4075]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, f1_score, confusion_matrix\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    inputs=torch.from_numpy(X_val).float()\n",
    "    outputs=model(inputs)\n",
    "    y_pred_prob=outputs.numpy()\n",
    "    y_pred=(y_pred_prob>0.5)\n",
    "\n",
    "report=classification_report(y_val,y_pred)\n",
    "f1score=f1_score(y_val,y_pred)\n",
    "roc=roc_auc_score(y_val,y_pred)\n",
    "matrix=confusion_matrix(y_val,y_pred)\n",
    "print(\"classification report\",report)\n",
    "print(\"f1 Score\",f1score)\n",
    "print(\"ROC AUC Score\",roc)\n",
    "print(\"Confusion Matrix\\n\",matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hello",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
